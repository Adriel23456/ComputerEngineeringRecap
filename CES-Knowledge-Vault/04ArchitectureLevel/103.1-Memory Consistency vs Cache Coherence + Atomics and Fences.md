---
Theme: Memory Consistency vs Cache Coherence + Atomics and Fences
Date created: 2026-01-28 12:00
tags: [ArchitectureLayer, Multiprocessor, Memory, Consistency, Coherence, Synchronization]
---

## ğŸ“š Idea/Concept

**Cache coherence** and **memory consistency** solve *different* problems in shared-memory multiprocessors:

- **Coherence** answers: *â€œIf multiple cores cache the same memory location, do they eventually agree on its value?â€*
- **Consistency** answers: *â€œIn what order can loads/stores from different cores become visible to each other?â€*

You can have a perfectly coherent system that is still confusing to program **without** a defined consistency model.

---

## 1) Cache Coherence (the â€œsingle addressâ€ rule)

### âœ… What coherence guarantees
For a **single memory address X**, coherence tries to ensure:
- **Write serialization**: all cores observe writes to X in the same order.
- **Read-your-writes** (per-core): a core should observe its own writes â€œas expectedâ€.
- **Eventually consistent visibility** (informally): if no more writes happen, everyone converges.

This is what protocols like **MSI/MESI/MOESI** enforce using states + invalidations/updates.

### ğŸ¯ Coherence is â€œper-locationâ€
Coherence is about **one address at a time**.
It does **NOT** guarantee anything about the ordering of **different addresses** (X vs Y).

---

## 2) Memory Consistency (the â€œmany addressesâ€ rule)

### âœ… What consistency models define
A consistency model defines the allowed behaviors of **loads/stores across multiple addresses** (X, Y, Z) when multiple cores execute concurrently.

It answers:
- Can a **load be observed before an earlier store**?
- Can two different cores observe operations in **different relative orders**?
- What reordering is allowed by the CPU, caches, store buffers, compiler, etc.?

### ğŸ”¥ The key source of â€œweirdnessâ€
Modern CPUs use performance tricks:
- **Store buffers** (store becomes visible to others later)
- **Invalidate queues**
- **Out-of-order execution**
- **Speculation**
- **Compiler reordering**

These can make other cores observe memory operations in an order that differs from the program order.

---

## 3) The classic trap: â€œCoherent but not intuitiveâ€

### Example: Message passing (two variables)
Assume initially `data = 0`, `flag = 0`.

**Core 0 (producer):**
- `data = 42;`
- `flag = 1;`

**Core 1 (consumer):**
- `while(flag == 0) { }`
- `print(data);`

### What you *want*
If Core 1 sees `flag == 1`, it should also see `data == 42`.

### What coherence alone allows
Coherence guarantees each variable is coherent **individually**.
But without a strong ordering guarantee, Core 1 could observe:
- `flag == 1` (visible earlier)
- `data == 0` (still not visible yet)

Thatâ€™s not a coherence violation. Itâ€™s an **ordering/consistency** issue.

---

## 4) Sequential Consistency (SC) â€” the â€œsimpleâ€ mental model

### Definition (intuitive)
**Sequential Consistency** says:
> The result is as if all operations from all cores were interleaved into a single global order, and each coreâ€™s operations appear in that order **in program order**.

### Why SC is expensive
SC restricts a lot of optimizations. Modern CPUs often implement weaker models to go faster.

---

## 5) Weaker models (the realistic world)

Many real systems allow some reordering, commonly:
- **Store â†’ Load** reordering (via store buffers)
- Sometimes **Load â†’ Load** and **Store â†’ Store** are constrained differently

Instead of forcing SC always, CPUs provide:
- **Atomic operations**
- **Memory fences (barriers)**
to let software â€œpin downâ€ ordering only when needed.

---

## 6) Atomics: operations that canâ€™t be â€œtornâ€ or interleaved incorrectly

### âœ… What an atomic guarantees (core idea)
An **atomic operation** is *indivisible* with respect to other threads.

Common atomic primitives:
- **CAS** (Compare-And-Swap)
- **LL/SC** (Load-Linked / Store-Conditional)
- **Fetch-and-Add**
- **Atomic exchange**

These are the building blocks of:
- locks (mutex/spinlock)
- lock-free data structures
- reference counting
- barriers

### Atomicity vs Ordering
Atomicity alone doesnâ€™t automatically fix ordering for other variables.
Thatâ€™s why we need **memory ordering semantics** or **fences**.

---

## 7) Memory fences (barriers): â€œdonâ€™t reorder across this lineâ€

A **fence** is a control that prevents certain memory reorders.

### Types (conceptual)
- **Load fence**: prevents loads after the fence from moving before it
- **Store fence**: prevents stores after the fence from moving before it
- **Full fence**: prevents both kinds across the boundary

Think:
> â€œEverything before the fence becomes visible before anything after the fence.â€

---

## 8) Acquire / Release: the â€œsurgicalâ€ ordering you usually want

Instead of a heavy full fence everywhere, most synchronization uses:

### Release (on the writer)
- Ensures all prior writes become visible **before** the releasing write becomes visible.

### Acquire (on the reader)
- Ensures subsequent reads/writes happen **after** the acquiring read observes the synchronization.

### Message passing fixed with Acquire/Release
- Core 0: `data=42;` then `store_release(flag, 1);`
- Core 1: `while(load_acquire(flag)==0) {}` then `read data`

Now: seeing `flag==1` implies `data==42` is visible.

---

## 9) The shortest mental model (super important)

### Coherence
â€œEveryone agrees on each variableâ€™s latest write order.â€

### Consistency
â€œEveryone agrees on **what ordering rules** exist across variables.â€

### Atomics + fences
â€œThe tools software uses to **create ordering** when it matters.â€

---

## 10) Practical consequences (why you care in real systems)

- **Locks** rely on atomic RMW + ordering (acquire/release).
- **Lock-free structures** rely on CAS/LLSC + strict ordering rules.
- **Bugs are rare and nondeterministic**: only show under timing differences.
- **Performance**: fences can be expensive; using acquire/release is often cheaper than full fences.

---

## ğŸ–¼ï¸ Recommended Image
- Diagram: two cores with store buffers + caches, showing `data` and `flag` visibility timing.
- Timeline visualization of writes/reads with and without fence/acquire-release.

---

## ğŸ”— Connections
- [[103-Cache Coherence Problem and Solutions]]
- [[106-MSI MESI and MOESI Protocols]]
- [[104-Snooping Cache Coherence Protocols]]
- [[105-Directory Based Cache Coherence]]
- [[101-Multiprocessor Types SMP AMP and DSM]]
- [[102-NUMA Architecture and Memory Placement]]
- [[100-Thread Level Speculation TLS]]
- [[085-Speculative Execution and Branch Prediction]]